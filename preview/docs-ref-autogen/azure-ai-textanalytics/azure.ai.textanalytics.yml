### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.ai.textanalytics.TextAnalyticsClient
  - azure.ai.textanalytics.DetectLanguageInput
  - azure.ai.textanalytics.TextDocumentInput
  - azure.ai.textanalytics.single_detect_language
  - azure.ai.textanalytics.single_recognize_entities
  - azure.ai.textanalytics.single_recognize_pii_entities
  - azure.ai.textanalytics.single_recognize_linked_entities
  - azure.ai.textanalytics.single_extract_key_phrases
  - azure.ai.textanalytics.single_analyze_sentiment
  - azure.ai.textanalytics.DetectedLanguage
  - azure.ai.textanalytics.RecognizeEntitiesResult
  - azure.ai.textanalytics.RecognizePiiEntitiesResult
  - azure.ai.textanalytics.DetectLanguageResult
  - azure.ai.textanalytics.NamedEntity
  - azure.ai.textanalytics.TextAnalyticsError
  - azure.ai.textanalytics.InnerError
  - azure.ai.textanalytics.ExtractKeyPhrasesResult
  - azure.ai.textanalytics.RecognizeLinkedEntitiesResult
  - azure.ai.textanalytics.AnalyzeSentimentResult
  - azure.ai.textanalytics.TextDocumentStatistics
  - azure.ai.textanalytics.DocumentError
  - azure.ai.textanalytics.LinkedEntity
  - azure.ai.textanalytics.LinkedEntityMatch
  - azure.ai.textanalytics.TextDocumentBatchStatistics
  - azure.ai.textanalytics.SentenceSentiment
  - azure.ai.textanalytics.SentimentConfidenceScorePerLabel
  - azure.ai.textanalytics.aio
  fullName: azure.ai.textanalytics
  kind: import
  langs:
  - python
  module: azure.ai.textanalytics
  name: textanalytics
  type: package
  uid: azure.ai.textanalytics
- example:
  - "Detecting language in a single string.<!--[!code-python[Main](les\\sample_single_detect_language.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\source_code\\\
    \\6\\\\azure-ai-textanalytics-1.0.0b1\\\\samples\\\\sample_single_detect_language.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   from azure.ai.textanalytics\
    \ import single_detect_language\n\n   text = \"I need to take my cat to the veterinarian.\"\
    \n\n   result = single_detect_language(\n       endpoint=self.endpoint,\n    \
    \   credential=self.key,\n       input_text=text,\n       country_hint=\"US\"\
    ,\n       show_stats=True\n   )\n\n   print(\"Language detected: {}\".format(result.primary_language.name))\n\
    \   print(\"Confidence score: {}\\n\".format(result.primary_language.score))\n\
    \   print(\"Document Statistics:\")\n   print(\"Text character count: {}\".format(result.statistics.character_count))\n\
    \   print(\"Transactions count: {}\".format(result.statistics.transaction_count))\n\
    \n   ````\n"
  exceptions:
  - description: ''
    type: ~azure.core.exceptions.HttpResponseError
  fullName: azure.ai.textanalytics.single_detect_language
  langs:
  - python
  module: azure.ai.textanalytics
  name: single_detect_language(endpoint, credential, input_text, country_hint='US',
    **kwargs)
  summary: 'Detect Language for a single document.


    Returns the detected language and a numeric score between zero and

    one. Scores close to one indicate 100% certainty that the identified

    language is true. See [https://aka.ms/talangs](https://aka.ms/talangs) for the
    list of enabled languages.'
  syntax:
    content: single_detect_language(endpoint, credential, input_text, country_hint='US',
      **kwargs)
    parameters:
    - description: 'Supported Cognitive Services endpoints (protocol and

        hostname, for example: [https://westus2.api.cognitive.microsoft.com](https://westus2.api.cognitive.microsoft.com)).'
      id: endpoint
      type:
      - str
    - description: 'Credentials needed for the client to connect to Azure.

        This can be the cognitive services subscription key or a token credential

        from azure.identity.'
      id: credential
      type:
      - str
      - azure.core.credentials.TokenCredential
    - description: The single string to detect language from.
      id: input_text
      type:
      - str
    - defaultValue: US
      description: 'The country hint for the text. Accepts two

        letter country codes specified by ISO 3166-1 alpha-2.

        Defaults to "US". If you don''t want to use a country hint,

        pass the empty string "".'
      id: country_hint
      type:
      - str
    return:
      description: An instance of DetectLanguageResult.
      type:
      - azure.ai.textanalytics.DetectLanguageResult
  type: function
  uid: azure.ai.textanalytics.single_detect_language
- example:
  - "Recognize entities in a single string.<!--[!code-python[Main](les\\sample_single_recognize_entities.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\source_code\\\
    \\6\\\\azure-ai-textanalytics-1.0.0b1\\\\samples\\\\sample_single_recognize_entities.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   from azure.ai.textanalytics\
    \ import single_recognize_entities\n\n   text = \"Microsoft was founded by Bill\
    \ Gates and Paul Allen on April 4, 1975,\" \\\n          \" to develop and sell\
    \ BASIC interpreters for the Altair 8800.\"\n\n   result = single_recognize_entities(\n\
    \       endpoint=self.endpoint,\n       credential=self.key,\n       input_text=text,\n\
    \       language=\"en\"\n   )\n\n   for entity in result.entities:\n       print(\"\
    Entity: {}\".format(entity.text))\n       print(\"Type: {}\".format(entity.type))\n\
    \       print(\"Confidence Score: {0:.3f}\\n\".format(entity.score))\n\n   ````\n"
  exceptions:
  - description: ''
    type: ~azure.core.exceptions.HttpResponseError
  fullName: azure.ai.textanalytics.single_recognize_entities
  langs:
  - python
  module: azure.ai.textanalytics
  name: single_recognize_entities(endpoint, credential, input_text, language='en',
    **kwargs)
  summary: 'Named Entity Recognition for a single document.


    Returns a list of general named entities in a given document.

    For a list of supported entity types, check: [https://aka.ms/taner](https://aka.ms/taner)

    For a list of enabled languages, check: [https://aka.ms/talangs](https://aka.ms/talangs)'
  syntax:
    content: single_recognize_entities(endpoint, credential, input_text, language='en',
      **kwargs)
    parameters:
    - description: 'Supported Cognitive Services endpoints (protocol and

        hostname, for example: [https://westus2.api.cognitive.microsoft.com](https://westus2.api.cognitive.microsoft.com)).'
      id: endpoint
      type:
      - str
    - description: 'Credentials needed for the client to connect to Azure.

        This can be the cognitive services subscription key or a token credential

        from azure.identity.'
      id: credential
      type:
      - str
      - azure.core.credentials.TokenCredential
    - description: The single string to recognize entities from.
      id: input_text
      type:
      - str
    - defaultValue: en
      description: 'This is the 2 letter ISO 639-1 representation

        of a language. For example, use "en" for English; "es" for Spanish etc. If

        not set, uses "en" for English as default.'
      id: language
      type:
      - str
    return:
      description: An instance of RecognizeEntitiesResult.
      type:
      - azure.ai.textanalytics.RecognizeEntitiesResult
  type: function
  uid: azure.ai.textanalytics.single_recognize_entities
- example:
  - "Recognize personally identifiable information entities in a single string.<!--[!code-python[Main](les\\\
    sample_single_recognize_pii_entities.py )]-->\n\n<!-- literal_block {\"ids\":\
    \ [], \"classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"source\"\
    : \"D:\\\\a\\\\1\\\\s\\\\source_code\\\\6\\\\azure-ai-textanalytics-1.0.0b1\\\\\
    samples\\\\sample_single_recognize_pii_entities.py\", \"xml:space\": \"preserve\"\
    , \"language\": \"python\", \"linenos\": false, \"highlight_args\": {\"linenostart\"\
    : 1}} -->\n\n````python\n\n   from azure.ai.textanalytics import single_recognize_pii_entities\n\
    \n   text = \"The employee's ABA number is 111000025 and his SSN is 555-55-5555.\"\
    \n\n   result = single_recognize_pii_entities(\n       endpoint=self.endpoint,\n\
    \       credential=self.key,\n       input_text=text,\n       language=\"en\"\n\
    \   )\n\n   for entity in result.entities:\n       print(\"Entity: {}\".format(entity.text))\n\
    \       print(\"Type: {}\".format(entity.type))\n       print(\"Confidence Score:\
    \ {}\\n\".format(entity.score))\n\n   ````\n"
  exceptions:
  - description: ''
    type: ~azure.core.exceptions.HttpResponseError
  fullName: azure.ai.textanalytics.single_recognize_pii_entities
  langs:
  - python
  module: azure.ai.textanalytics
  name: single_recognize_pii_entities(endpoint, credential, input_text, language='en',
    **kwargs)
  summary: 'Recognize entities containing personal information for a single document.


    Returns a list of personal information entities ("SSN",

    "Bank Account", etc) in the document.  For the list of supported entity types,

    check [https://aka.ms/tanerpii](https://aka.ms/tanerpii). See [https://aka.ms/talangs](https://aka.ms/talangs)

    for the list of enabled languages.'
  syntax:
    content: single_recognize_pii_entities(endpoint, credential, input_text, language='en',
      **kwargs)
    parameters:
    - description: 'Supported Cognitive Services endpoints (protocol and

        hostname, for example: [https://westus2.api.cognitive.microsoft.com](https://westus2.api.cognitive.microsoft.com)).'
      id: endpoint
      type:
      - str
    - description: 'Credentials needed for the client to connect to Azure.

        This can be the cognitive services subscription key or a token credential

        from azure.identity.'
      id: credential
      type:
      - str
      - azure.core.credentials.TokenCredential
    - description: The single string to recognize entities from.
      id: input_text
      type:
      - str
    - defaultValue: en
      description: 'This is the 2 letter ISO 639-1 representation

        of a language. For example, use "en" for English; "es" for Spanish etc. If

        not set, uses "en" for English as default.'
      id: language
      type:
      - str
    return:
      description: An instance of RecognizePiiEntitiesResult.
      type:
      - azure.ai.textanalytics.RecognizePiiEntitiesResult
  type: function
  uid: azure.ai.textanalytics.single_recognize_pii_entities
- example:
  - "Recognize linked entities in a single string.<!--[!code-python[Main](les\\sample_single_recognize_linked_entities.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\source_code\\\
    \\6\\\\azure-ai-textanalytics-1.0.0b1\\\\samples\\\\sample_single_recognize_linked_entities.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   from azure.ai.textanalytics\
    \ import single_recognize_linked_entities\n\n   text = \"Easter Island, a Chilean\
    \ territory, is a remote volcanic island in Polynesia. \" \\\n          \"Its\
    \ native name is Rapa Nui.\"\n\n   result = single_recognize_linked_entities(\n\
    \       endpoint=self.endpoint,\n       credential=self.key,\n       input_text=text,\n\
    \       language=\"en\"\n   )\n\n   for entity in result.entities:\n       print(\"\
    Entity: {}\".format(entity.name))\n       print(\"Url: {}\".format(entity.url))\n\
    \       print(\"Data Source: {}\\n\".format(entity.data_source))\n       print(\"\
    Where this entity appears in the text:\")\n       for idx, match in enumerate(entity.matches):\n\
    \           print(\"Match {}: {}\".format(idx+1, match.text))\n           print(\"\
    Score: {0:.3f}\".format(match.score))\n           print(\"Offset: {}\".format(match.offset))\n\
    \           print(\"Length: {}\\n\".format(match.length))\n\n   ````\n"
  exceptions:
  - description: ''
    type: ~azure.core.exceptions.HttpResponseError
  fullName: azure.ai.textanalytics.single_recognize_linked_entities
  langs:
  - python
  module: azure.ai.textanalytics
  name: single_recognize_linked_entities(endpoint, credential, input_text, language='en',
    **kwargs)
  summary: 'Recognize linked entities from a well-known knowledge base

    for a single document.


    Returns a list of recognized entities with links to a

    well-known knowledge base. See [https://aka.ms/talangs](https://aka.ms/talangs)
    for

    supported languages in Text Analytics API.'
  syntax:
    content: single_recognize_linked_entities(endpoint, credential, input_text, language='en',
      **kwargs)
    parameters:
    - description: 'Supported Cognitive Services endpoints (protocol and

        hostname, for example: [https://westus2.api.cognitive.microsoft.com](https://westus2.api.cognitive.microsoft.com)).'
      id: endpoint
      type:
      - str
    - description: 'Credentials needed for the client to connect to Azure.

        This can be the cognitive services subscription key or a token credential

        from azure.identity.'
      id: credential
      type:
      - str
      - azure.core.credentials.TokenCredential
    - description: The single string to recognize entities from.
      id: input_text
      type:
      - str
    - defaultValue: en
      description: 'This is the 2 letter ISO 639-1 representation

        of a language. For example, use "en" for English; "es" for Spanish etc. If

        not set, uses "en" for English as default.'
      id: language
      type:
      - str
    return:
      description: An instance of RecognizeLinkedEntitiesResult
      type:
      - azure.ai.textanalytics.RecognizeLinkedEntitiesResult
  type: function
  uid: azure.ai.textanalytics.single_recognize_linked_entities
- example:
  - "Extract key phrases in a single string.<!--[!code-python[Main](les\\sample_single_extract_key_phrases.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\source_code\\\
    \\6\\\\azure-ai-textanalytics-1.0.0b1\\\\samples\\\\sample_single_extract_key_phrases.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   from azure.ai.textanalytics\
    \ import single_extract_key_phrases\n\n   text = \"Redmond is a city in King County,\
    \ Washington, United States, located 15 miles east of Seattle.\"\n\n   result\
    \ = single_extract_key_phrases(\n       endpoint=self.endpoint,\n       credential=self.key,\n\
    \       input_text=text,\n       language=\"en\"\n   )\n\n   print(\"Key phrases\
    \ found:\\n\")\n   for phrase in result.key_phrases:\n       print(phrase)\n\n\
    \   ````\n"
  exceptions:
  - description: ''
    type: ~azure.core.exceptions.HttpResponseError
  fullName: azure.ai.textanalytics.single_extract_key_phrases
  langs:
  - python
  module: azure.ai.textanalytics
  name: single_extract_key_phrases(endpoint, credential, input_text, language='en',
    **kwargs)
  summary: 'Extract Key Phrases for a single document.


    Returns a list of strings denoting the key phrases in the input

    text. See [https://aka.ms/talangs](https://aka.ms/talangs) for the list of enabled

    languages.'
  syntax:
    content: single_extract_key_phrases(endpoint, credential, input_text, language='en',
      **kwargs)
    parameters:
    - description: 'Supported Cognitive Services endpoints (protocol and

        hostname, for example: [https://westus2.api.cognitive.microsoft.com](https://westus2.api.cognitive.microsoft.com)).'
      id: endpoint
      type:
      - str
    - description: 'Credentials needed for the client to connect to Azure.

        This can be the cognitive services subscription key or a token credential

        from azure.identity.'
      id: credential
      type:
      - str
      - azure.core.credentials.TokenCredential
    - description: The single string to extract key phrases from.
      id: input_text
      type:
      - str
    - defaultValue: en
      description: 'This is the 2 letter ISO 639-1 representation

        of a language. For example, use "en" for English; "es" for Spanish etc. If

        not set, uses "en" for English as default.'
      id: language
      type:
      - str
    return:
      description: An instance of ExtractKeyPhrasesResult
      type:
      - azure.ai.textanalytics.ExtractKeyPhrasesResult
  type: function
  uid: azure.ai.textanalytics.single_extract_key_phrases
- example:
  - "Analyze sentiment in a single string.<!--[!code-python[Main](les\\sample_single_analyze_sentiment.py\
    \ )]-->\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"\
    dupnames\": [], \"backrefs\": [], \"source\": \"D:\\\\a\\\\1\\\\s\\\\source_code\\\
    \\6\\\\azure-ai-textanalytics-1.0.0b1\\\\samples\\\\sample_single_analyze_sentiment.py\"\
    , \"xml:space\": \"preserve\", \"language\": \"python\", \"linenos\": false, \"\
    highlight_args\": {\"linenostart\": 1}} -->\n\n````python\n\n   from azure.ai.textanalytics\
    \ import single_analyze_sentiment\n\n   text = \"I visited the restaurant last\
    \ week. The portions were very generous. However, I did not like what \" \\\n\
    \          \"I ordered.\"\n\n   result = single_analyze_sentiment(\n       endpoint=self.endpoint,\n\
    \       credential=self.key,\n       input_text=text,\n       language=\"en\"\n\
    \   )\n\n   print(\"Overall sentiment: {}\".format(result.sentiment))\n   print(\"\
    Overall scores: positive={0:.3f}; neutral={1:.3f}; negative={2:.3f} \\n\".format(\n\
    \       result.document_scores.positive,\n       result.document_scores.neutral,\n\
    \       result.document_scores.negative,\n   ))\n\n   for idx, sentence in enumerate(result.sentences):\n\
    \       print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n\
    \       print(\"Offset: {}\".format(sentence.offset))\n       print(\"Length:\
    \ {}\".format(sentence.length))\n       print(\"Sentence score: positive={0:.3f};\
    \ neutral={1:.3f}; negative={2:.3f} \\n\".format(\n           sentence.sentence_scores.positive,\n\
    \           sentence.sentence_scores.neutral,\n           sentence.sentence_scores.negative,\n\
    \       ))\n\n   ````\n"
  exceptions:
  - description: ''
    type: ~azure.core.exceptions.HttpResponseError
  fullName: azure.ai.textanalytics.single_analyze_sentiment
  langs:
  - python
  module: azure.ai.textanalytics
  name: single_analyze_sentiment(endpoint, credential, input_text, language='en',
    **kwargs)
  summary: 'Analyze sentiment in a single document.


    Returns a sentiment prediction, as well as sentiment scores for

    each sentiment class (Positive, Negative, and Neutral) for the document

    and each sentence within it. See [https://aka.ms/talangs](https://aka.ms/talangs)
    for the list

    of enabled languages.'
  syntax:
    content: single_analyze_sentiment(endpoint, credential, input_text, language='en',
      **kwargs)
    parameters:
    - description: 'Supported Cognitive Services endpoints (protocol and

        hostname, for example: [https://westus2.api.cognitive.microsoft.com](https://westus2.api.cognitive.microsoft.com)).'
      id: endpoint
      type:
      - str
    - description: 'Credentials needed for the client to connect to Azure.

        This can be the cognitive services subscription key or a token credential

        from azure.identity.'
      id: credential
      type:
      - str
      - azure.core.credentials.TokenCredential
    - description: The single string to analyze sentiment from.
      id: input_text
      type:
      - str
    - defaultValue: en
      description: 'This is the 2 letter ISO 639-1 representation

        of a language. For example, use "en" for English; "es" for Spanish etc. If

        not set, uses "en" for English as default.'
      id: language
      type:
      - str
    return:
      description: An instance of AnalyzeSentimentResult
      type:
      - azure.ai.textanalytics.AnalyzeSentimentResult
  type: function
  uid: azure.ai.textanalytics.single_analyze_sentiment
references:
- fullName: azure.ai.textanalytics.TextAnalyticsClient
  isExternal: false
  name: TextAnalyticsClient
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.TextAnalyticsClient
- fullName: azure.ai.textanalytics.DetectLanguageInput
  isExternal: false
  name: DetectLanguageInput
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.DetectLanguageInput
- fullName: azure.ai.textanalytics.TextDocumentInput
  isExternal: false
  name: TextDocumentInput
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.TextDocumentInput
- fullName: azure.ai.textanalytics.single_detect_language
  isExternal: false
  name: single_detect_language(endpoint, credential, input_text, country_hint='US',
    **kwargs)
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.single_detect_language
- fullName: azure.ai.textanalytics.single_recognize_entities
  isExternal: false
  name: single_recognize_entities(endpoint, credential, input_text, language='en',
    **kwargs)
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.single_recognize_entities
- fullName: azure.ai.textanalytics.single_recognize_pii_entities
  isExternal: false
  name: single_recognize_pii_entities(endpoint, credential, input_text, language='en',
    **kwargs)
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.single_recognize_pii_entities
- fullName: azure.ai.textanalytics.single_recognize_linked_entities
  isExternal: false
  name: single_recognize_linked_entities(endpoint, credential, input_text, language='en',
    **kwargs)
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.single_recognize_linked_entities
- fullName: azure.ai.textanalytics.single_extract_key_phrases
  isExternal: false
  name: single_extract_key_phrases(endpoint, credential, input_text, language='en',
    **kwargs)
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.single_extract_key_phrases
- fullName: azure.ai.textanalytics.single_analyze_sentiment
  isExternal: false
  name: single_analyze_sentiment(endpoint, credential, input_text, language='en',
    **kwargs)
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.single_analyze_sentiment
- fullName: azure.ai.textanalytics.DetectedLanguage
  isExternal: false
  name: DetectedLanguage
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.DetectedLanguage
- fullName: azure.ai.textanalytics.RecognizeEntitiesResult
  isExternal: false
  name: RecognizeEntitiesResult
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.RecognizeEntitiesResult
- fullName: azure.ai.textanalytics.RecognizePiiEntitiesResult
  isExternal: false
  name: RecognizePiiEntitiesResult
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.RecognizePiiEntitiesResult
- fullName: azure.ai.textanalytics.DetectLanguageResult
  isExternal: false
  name: DetectLanguageResult
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.DetectLanguageResult
- fullName: azure.ai.textanalytics.NamedEntity
  isExternal: false
  name: NamedEntity
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.NamedEntity
- fullName: azure.ai.textanalytics.TextAnalyticsError
  isExternal: false
  name: TextAnalyticsError
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.TextAnalyticsError
- fullName: azure.ai.textanalytics.InnerError
  isExternal: false
  name: InnerError
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.InnerError
- fullName: azure.ai.textanalytics.ExtractKeyPhrasesResult
  isExternal: false
  name: ExtractKeyPhrasesResult
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.ExtractKeyPhrasesResult
- fullName: azure.ai.textanalytics.RecognizeLinkedEntitiesResult
  isExternal: false
  name: RecognizeLinkedEntitiesResult
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.RecognizeLinkedEntitiesResult
- fullName: azure.ai.textanalytics.AnalyzeSentimentResult
  isExternal: false
  name: AnalyzeSentimentResult
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.AnalyzeSentimentResult
- fullName: azure.ai.textanalytics.TextDocumentStatistics
  isExternal: false
  name: TextDocumentStatistics
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.TextDocumentStatistics
- fullName: azure.ai.textanalytics.DocumentError
  isExternal: false
  name: DocumentError
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.DocumentError
- fullName: azure.ai.textanalytics.LinkedEntity
  isExternal: false
  name: LinkedEntity
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.LinkedEntity
- fullName: azure.ai.textanalytics.LinkedEntityMatch
  isExternal: false
  name: LinkedEntityMatch
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.LinkedEntityMatch
- fullName: azure.ai.textanalytics.TextDocumentBatchStatistics
  isExternal: false
  name: TextDocumentBatchStatistics
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.TextDocumentBatchStatistics
- fullName: azure.ai.textanalytics.SentenceSentiment
  isExternal: false
  name: SentenceSentiment
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.SentenceSentiment
- fullName: azure.ai.textanalytics.SentimentConfidenceScorePerLabel
  isExternal: false
  name: SentimentConfidenceScorePerLabel
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.SentimentConfidenceScorePerLabel
- fullName: azure.ai.textanalytics.aio
  isExternal: false
  name: aio
  parent: azure.ai.textanalytics
  uid: azure.ai.textanalytics.aio
