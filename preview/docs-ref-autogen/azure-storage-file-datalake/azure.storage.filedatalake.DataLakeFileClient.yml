### YamlMime:UniversalReference
api_name: []
items:
- children:
  - azure.storage.filedatalake.DataLakeFileClient.append_data
  - azure.storage.filedatalake.DataLakeFileClient.create_file
  - azure.storage.filedatalake.DataLakeFileClient.delete_file
  - azure.storage.filedatalake.DataLakeFileClient.flush_data
  - azure.storage.filedatalake.DataLakeFileClient.from_connection_string
  - azure.storage.filedatalake.DataLakeFileClient.get_file_properties
  - azure.storage.filedatalake.DataLakeFileClient.read_file
  - azure.storage.filedatalake.DataLakeFileClient.rename_file
  class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient
  inheritance:
  - inheritance:
    - inheritance:
      - type: builtins.object
      type: azure.storage.filedatalake._shared.base_client.StorageAccountHostsMixin
    type: azure.storage.filedatalake._path_client.PathClient
  langs:
  - python
  module: azure.storage.filedatalake
  name: DataLakeFileClient
  summary: A client to interact with the DataLake file, even if the file may not yet
    exist.
  syntax:
    content: DataLakeFileClient(account_url, file_system_name, file_path, credential=None,
      **kwargs)
    parameters:
    - description: The URI to the storage account.
      id: account_url
      type:
      - str
    - description: The file system for the directory or files.
      id: file_system_name
      type:
      - str
    - description: 'The whole file path, so that to interact with a specific file.

        eg. "{directory}/{subdirectory}/{file}"'
      id: file_path
      type:
      - str
    - description: 'The credentials with which to authenticate. This is optional if
        the

        account URL already has a SAS token. The value can be a SAS token string,
        and account

        shared access key, or an instance of a TokenCredentials class from azure.identity.

        If the URL already has a SAS token, specifying an explicit credential will
        take priority.'
      id: credential
    variables:
    - description: The full endpoint URL to the file system, including SAS token if
        used.
      id: url
      type:
      - str
    - description: The full primary endpoint URL.
      id: primary_endpoint
      type:
      - str
    - description: The hostname of the primary endpoint.
      id: primary_hostname
      type:
      - str
  type: class
  uid: azure.storage.filedatalake.DataLakeFileClient
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.append_data
  langs:
  - python
  module: azure.storage.filedatalake
  name: append_data(data, offset, length=None, **kwargs)
  summary: Append data to the file.
  syntax:
    content: append_data(data, offset, length=None, **kwargs)
    parameters:
    - description: Content to be appended to file
      id: data
    - description: start position of the data to be appended to.
      id: offset
    - defaultValue: None
      description: Size of the data in bytes.
      id: length
    return:
      description: dict of the response header
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.append_data
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.create_file
  langs:
  - python
  module: azure.storage.filedatalake
  name: create_file(content_settings=None, metadata=None, **kwargs)
  summary: Create a new file.
  syntax:
    content: create_file(content_settings=None, metadata=None, **kwargs)
    parameters:
    - defaultValue: None
      description: ContentSettings object used to set path properties.
      id: content_settings
      type:
      - azure.storage.filedatalake.ContentSettings
    - defaultValue: None
      description: Name-value pairs associated with the blob as metadata.
      id: metadata
      type:
      - dict(str, str)
    return:
      description: response dict (Etag and last modified).
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.create_file
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.delete_file
  langs:
  - python
  module: azure.storage.filedatalake
  name: delete_file(**kwargs)
  summary: Marks the specified file for deletion.
  syntax:
    content: delete_file(**kwargs)
    parameters: []
    return:
      description: None
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.delete_file
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.flush_data
  langs:
  - python
  module: azure.storage.filedatalake
  name: flush_data(offset, retain_uncommitted_data=False, **kwargs)
  summary: Commit the previous appended data.
  syntax:
    content: flush_data(offset, retain_uncommitted_data=False, **kwargs)
    parameters:
    - description: 'offset is equal to the length of the file after commit the

        previous appended data.'
      id: offset
    - defaultValue: 'False'
      description: 'Valid only for flush operations.  If

        "true", uncommitted data is retained after the flush operation

        completes; otherwise, the uncommitted data is deleted after the flush

        operation.  The default is false.  Data at offsets less than the

        specified position are written to the file when flush succeeds, but

        this optional parameter allows data after the flush position to be

        retained for a future flush operation.'
      id: retain_uncommitted_data
      type:
      - bool
    return:
      description: response header in dict
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.flush_data
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.from_connection_string
  langs:
  - python
  module: azure.storage.filedatalake
  name: from_connection_string(conn_str, file_system_name, file_path, credential=None,
    **kwargs)
  summary: 'Create DataLakeFileClient from a Connection String.



    :return a DataLakeFileClient

    :rtype ~azure.storage.filedatalake.DataLakeFileClient'
  syntax:
    content: from_connection_string(conn_str, file_system_name, file_path, credential=None,
      **kwargs)
    parameters:
    - description: A connection string to an Azure Storage account.
      id: conn_str
      type:
      - str
    - description: The name of file system to interact with.
      id: file_system_name
      type:
      - str
    - description: The name of directory to interact with. The directory is under
        file system.
      id: directory_name
      type:
      - str
    - description: The name of file to interact with. The file is under directory.
      id: file_name
      type:
      - str
    - defaultValue: None
      description: 'The credentials with which to authenticate. This is optional if
        the

        account URL already has a SAS token, or the connection string already has
        shared

        access key values. The value can be a SAS token string, and account shared
        access

        key, or an instance of a TokenCredentials class from azure.identity.

        Credentials provided here will take precedence over those in the connection
        string.'
      id: credential
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.from_connection_string
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.get_file_properties
  langs:
  - python
  module: azure.storage.filedatalake
  name: get_file_properties(**kwargs)
  summary: 'Returns all user-defined metadata, standard HTTP properties, and

    system properties for the file. It does not return the content of the file.'
  syntax:
    content: get_file_properties(**kwargs)
    parameters: []
    return:
      type:
      - FileProperties
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.get_file_properties
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.read_file
  langs:
  - python
  module: azure.storage.filedatalake
  name: read_file(offset=None, length=None, stream=None, **kwargs)
  summary: 'Download a file from the service. Return the downloaded data in bytes
    or

    write the downloaded data into user provided stream and return the written size.'
  syntax:
    content: read_file(offset=None, length=None, stream=None, **kwargs)
    parameters:
    - defaultValue: None
      description: 'Start of byte range to use for downloading a section of the file.

        Must be set if length is provided.'
      id: offset
      type:
      - int
    - defaultValue: None
      description: 'Number of bytes to read from the stream. This is optional, but

        should be supplied for optimal performance.'
      id: length
      type:
      - int
    - defaultValue: None
      description: User provided stream to write the downloaded data into.
      id: stream
      type:
      - int
    return:
      description: downloaded data or the size of data written into the provided stream
      type:
      - bytes
      - int
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.read_file
- class: azure.storage.filedatalake.DataLakeFileClient
  fullName: azure.storage.filedatalake.DataLakeFileClient.rename_file
  langs:
  - python
  module: azure.storage.filedatalake
  name: rename_file(rename_destination, **kwargs)
  summary: Rename the source file.
  syntax:
    content: rename_file(rename_destination, **kwargs)
    parameters:
    - description: 'the new file name the user want to rename to.

        The value must have the following format: "{filesystem}/{directory}/{subdirectory}/{file}".'
      id: rename_destination
      type:
      - str
    - description: ContentSettings object used to set path properties.
      id: content_settings
      type:
      - azure.storage.filedatalake.ContentSettings
  type: method
  uid: azure.storage.filedatalake.DataLakeFileClient.rename_file
references:
- fullName: azure.storage.filedatalake.DataLakeFileClient.append_data
  isExternal: false
  name: append_data(data, offset, length=None, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.append_data
- fullName: azure.storage.filedatalake.DataLakeFileClient.create_file
  isExternal: false
  name: create_file(content_settings=None, metadata=None, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.create_file
- fullName: azure.storage.filedatalake.DataLakeFileClient.delete_file
  isExternal: false
  name: delete_file(**kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.delete_file
- fullName: azure.storage.filedatalake.DataLakeFileClient.flush_data
  isExternal: false
  name: flush_data(offset, retain_uncommitted_data=False, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.flush_data
- fullName: azure.storage.filedatalake.DataLakeFileClient.from_connection_string
  isExternal: false
  name: from_connection_string(conn_str, file_system_name, file_path, credential=None,
    **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.from_connection_string
- fullName: azure.storage.filedatalake.DataLakeFileClient.get_file_properties
  isExternal: false
  name: get_file_properties(**kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.get_file_properties
- fullName: azure.storage.filedatalake.DataLakeFileClient.read_file
  isExternal: false
  name: read_file(offset=None, length=None, stream=None, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.read_file
- fullName: azure.storage.filedatalake.DataLakeFileClient.rename_file
  isExternal: false
  name: rename_file(rename_destination, **kwargs)
  parent: azure.storage.filedatalake.DataLakeFileClient
  uid: azure.storage.filedatalake.DataLakeFileClient.rename_file
- fullName: dict(str, str)
  name: dict(str, str)
  spec.python:
  - fullName: dict
    name: dict
    uid: dict
  - fullName: (
    name: (
  - fullName: str
    name: str
    uid: str
  - fullName: ', '
    name: ', '
  - fullName: str
    name: str
    uid: str
  - fullName: )
    name: )
  uid: dict(str, str)
